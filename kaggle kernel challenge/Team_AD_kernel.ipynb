{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Methods AMMI 2020\n",
    "This is a data challenge for the course \"Kernel Methods\" for AMMI 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import cvxopt\n",
    "from cvxopt import matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data loading and processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training features and label\n",
    "trainx_df = pd.read_csv(\"Xtr.csv\")\n",
    "trainx_df_mat = pd.read_csv(\"Xtr_mat100.csv\",header=None, sep=' ')\n",
    "\n",
    "trainy_df = pd.read_csv(\"Ytr.csv\")\n",
    "\n",
    "# Test features and label\n",
    "test_df = pd.read_csv(\"Xte.csv\")\n",
    "test_df_mat = pd.read_csv(\"Xte_mat100.csv\",header=None, sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                seq\n",
       "0   0  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...\n",
       "1   1  CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...\n",
       "2   2  GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...\n",
       "3   3  GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...\n",
       "4   4  GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC..."
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      "Id     2000 non-null int64\n",
      "seq    2000 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 31.4+ KB\n"
     ]
    }
   ],
   "source": [
    "trainx_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Bound\n",
       "0   0      1\n",
       "1   1      0\n",
       "2   2      1\n",
       "3   3      0\n",
       "4   4      1"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      "Id       2000 non-null int64\n",
      "Bound    2000 non-null int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 31.4 KB\n"
     ]
    }
   ],
   "source": [
    "trainy_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id       2000\n",
       "Bound    2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape (2000, 2)\n",
      "Label shape (2000,)\n",
      "Test shape (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training shape\",trainx_df.shape)\n",
    "print(\"Label shape\",trainy.shape)\n",
    "print(\"Test shape\",test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation dataframe into numpy\n",
    "from sklearn import preprocessing\n",
    "trainx = np.array(trainx_df)\n",
    "trainx_mat = np.array(trainx_df_mat)\n",
    "#trainx_mat = preprocessing.scale(trainx_mat, axis=1)\n",
    "\n",
    "trainy = np.array(trainy_df)[:,1]\n",
    "\n",
    "test = np.array(test_df)\n",
    "test_mat = np.array(test_df_mat)\n",
    "#test_mat = preprocessing.scale(test_mat,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try with Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_from_median(X):\n",
    "    '''\n",
    "    Returns the median of ||Xi-Xj||\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    X: (n, p) matrix\n",
    "    '''\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "sigma = sigma_from_median(trainx_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16268075594669312"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "## kernel function\n",
    "def GaussKernel(X1, X2, sigma = 0.16268075594669312):\n",
    "    n, m = X1.shape[0], X2.shape[0]\n",
    "    K = np.zeros((n,m))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            K[i,j] = np.exp(-((np.linalg.norm(X1[i]-X2[j]))**2)/(2*sigma**2))\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel matrix\n",
    "kernel_x = GaussKernel(trainx_mat,trainx_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"gaussian_kernel.npy\",kernel_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's implement SVM with Gaussian Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We solve the optimization problem $$\\left\\{\\begin{matrix}\n",
    "\\underset{\\alpha \\in \\mathbb{R}^{n}}{\\text{max}} \\hspace{0.1cm} 2\\alpha^{T}y - \\alpha^{T}K\\alpha \\\\ 0 \\leq y_i\\alpha_i \\leq \\frac{1}{2\\lambda n}, \\hspace{0.5cm} \\text{for} \\hspace{0.3cm} i = 0...n\n",
    "\\end{matrix}\\right. \\Leftrightarrow \\left\\{\\begin{matrix}\n",
    "\\underset{\\alpha \\in \\mathbb{R}^{n}}{\\text{min}} \\hspace{0.1cm} \\frac{1}{2}\\alpha^{T}P\\alpha + q^{t}\\alpha  \\\\ G\\alpha \\leq h\n",
    "\\end{matrix}\\right.   $$\n",
    "Where $\\tilde{P} = K$, $q = -y$, $G =\\binom{\\text{Diag}(y)}{-\\text{Diag}(y)} $ and $h=\\binom{\\frac{1}{2\\lambda n}\\mathcal{1}}{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_dual_SVM(K,y, lambda_ = 1):\n",
    "    n = K.shape[0] \n",
    "    G = np.vstack((np.diag(y),-np.diag(y)))\n",
    "    h = np.vstack(((1/(2*lambda_*n))*np.ones((n,1)),np.zeros((n,1))))\n",
    "\n",
    "    P = K\n",
    "    q = -y.reshape(-1,1)\n",
    "    #P = .5 * (P + P.T)  # make sure P is symmetric\n",
    "    args = [matrix(P), matrix(q)]\n",
    "\n",
    "    args.extend([matrix(G), matrix(h)])\n",
    "\n",
    "    sol = cvxopt.solvers.qp(*args) \n",
    "\n",
    "    return np.array(sol['x']).reshape((P.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  2.0237e+08 -6.1851e+09  7e+09  8e-02  3e-11\n",
      " 1:  1.0743e+08 -8.0930e+08  9e+08  1e-02  3e-11\n",
      " 2:  4.4887e+07 -1.8142e+08  2e+08  2e-03  2e-11\n",
      " 3:  1.5047e+07 -4.9446e+07  6e+07  3e-04  2e-11\n",
      " 4:  5.3234e+06 -1.9840e+07  3e+07  6e-05  1e-11\n",
      " 5:  1.5632e+06 -7.0446e+06  9e+06  2e-16  9e-12\n",
      " 6:  2.5345e+05 -7.5716e+05  1e+06  2e-16  5e-12\n",
      " 7:  1.1636e+04 -9.8212e+04  1e+05  2e-16  2e-12\n",
      " 8: -1.6325e+04 -2.9916e+04  1e+04  2e-16  1e-12\n",
      " 9: -1.8620e+04 -2.1623e+04  3e+03  2e-16  8e-13\n",
      "10: -1.9049e+04 -1.9613e+04  6e+02  2e-16  8e-13\n",
      "11: -1.9150e+04 -1.9202e+04  5e+01  2e-16  8e-13\n",
      "12: -1.9163e+04 -1.9165e+04  2e+00  2e-16  8e-13\n",
      "13: -1.9164e+04 -1.9164e+04  7e-02  2e-16  8e-13\n",
      "14: -1.9164e+04 -1.9164e+04  3e-03  2e-16  8e-13\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "alpha = solve_dual_SVM(kernel_x,2*trainy-1.,lambda_= 0.0000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel matrix test\n",
    "kernel_test = GaussKernel(trainx_mat,test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"gaussian_kernel_test.npy\",kernel_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = alpha.reshape(-1,1).T.dot(kernel_test)\n",
    "prediction[prediction>0] = 1\n",
    "prediction[prediction <0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "train_prediction = (np.sign(alpha.reshape(-1,1).T.dot(kernel_x))+1)/2\n",
    "print('Train Accuracy :',1- np.abs(train_prediction - trainy).sum()/trainy.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.squeeze(prediction).astype(int)\n",
    "df = pd.DataFrame({'Bound': predictions,\n",
    "                   'Id': np.arange(len(predictions))})\n",
    "df = df[['Id','Bound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"gaussian_SVM.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrum Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kernel functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubString(mString, spectrum):\n",
    "    \n",
    "    dictionnary = {}\n",
    "    for i in range(len(mString)-spectrum+1):\n",
    "        if mString[i:i+spectrum] in dictionnary:\n",
    "            dictionnary[mString[i:i+spectrum]] += 1\n",
    "        else:\n",
    "            dictionnary[mString[i:i+spectrum]] = 1\n",
    "    return dictionnary\n",
    "\n",
    "def SpectrumKernelFunction(mString1, mString2, spectrum):\n",
    "    dictionnary1 = getSubString(mString1, spectrum)\n",
    "    dictionnary2 = getSubString(mString2, spectrum)\n",
    "    \n",
    "    kernel = 0\n",
    "    for i in dictionnary1:\n",
    "        if i in dictionnary2:\n",
    "            kernel += dictionnary1[i] * dictionnary2[i]\n",
    "    return kernel\n",
    "\n",
    "## We should improve this function to take less time\n",
    "def SpectrumKernelMatrix_train(serie,spectrum):\n",
    "    n = serie.shape[0]\n",
    "    K = np.zeros((n,n))\n",
    "    for i,seq1 in enumerate(serie):\n",
    "        for j,seq2 in enumerate(serie):\n",
    "            if i <= j :\n",
    "                K[i,j] = SpectrumKernelFunction(seq1, seq2, spectrum)\n",
    "                K[j,i] = K[i,j]\n",
    "    return(K)\n",
    "\n",
    "def SpectrumKernelMatrix_test(serie_train, serie_test, spectrum):\n",
    "    n = serie_train.shape[0]\n",
    "    m = serie_test.shape[0]\n",
    "    K = np.zeros((n,m))\n",
    "    for i,seq1 in enumerate(serie_test):\n",
    "        for j,seq2 in enumerate(serie_train):\n",
    "            K[j,i] = SpectrumKernelFunction(seq1, seq2, spectrum)\n",
    "    return(K)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paralize computation and kernel matrix contruction for training set\n",
    "\n",
    "if os.path.isfile(\"spectrum_kernel_Xtr.npy\"):\n",
    "    K_Xtr = np.load(\"spectrum_kernel_Xtr.npy\")\n",
    "else:\n",
    "    K_Xtr = SpectrumKernelMatrix_train(trainx_df['seq'],spectrum=3)\n",
    "    np.save(\"spectrum_kernel_Xtr.npy\",K_Xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paralize computation and kernel matrix contruction for test set\n",
    "if os.path.isfile(\"spectrum_kernel_Xte.npy\"):\n",
    "    K_Xte = np.load(\"spectrum_kernel_Xte.npy\")\n",
    "else:\n",
    "    K_Xte = SpectrumKernelMatrix_test(trainx_df['seq'],test_df['seq'],spectrum=3)\n",
    "    np.save(\"spectrum_kernel_Xte.npy\",K_Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Solve the standard weighted kernel logisitc regression (WKLR) problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "### We need to improve this ####\n",
    "def sqrtMatrix(W):\n",
    "    # To compute the square root of a symetric positive matrix\n",
    "    D,V = np.linalg.eig(W)\n",
    "    return np.dot(np.dot(V,np.diag(np.sqrt(D))),np.linalg.inv(V))\n",
    "\n",
    "def solveWKRR(K,W,z,lambda_):\n",
    "    n = K.shape[0]\n",
    "    W_sqrt = np.real(sqrtMatrix(W))\n",
    "    \n",
    "    temp = np.dot(np.dot(W_sqrt,K),W_sqrt) +  n*lambda_*np.eye(n)\n",
    "    return  np.dot(W_sqrt,np.linalg.solve(temp,np.dot(W_sqrt,z)))\n",
    "\n",
    "def solveKLR(K,y,alpha0,lambda_ = 0.00000001,itermax = 30, eps =1e-6):\n",
    "    n = K.shape[0]\n",
    "    \n",
    "    iter_ = 0\n",
    "    last_alpha = 10*alpha0 + np.ones(alpha0.shape)\n",
    "    alpha = alpha0\n",
    "    \n",
    "    while (iter_< itermax) and (np.linalg.norm(last_alpha-alpha)>eps) :         \n",
    "        print(iter_,np.linalg.norm(last_alpha-alpha))\n",
    "        last_alpha = alpha\n",
    "        m = np.dot(K,alpha)\n",
    "        P = np.zeros((n,1))\n",
    "        W = np.zeros((n,n))\n",
    "        z = np.zeros((n,1))\n",
    "        for i in range(n):\n",
    "            P[i,0] = -sigmoid(-y[i]*m[i])\n",
    "            W[i,i] = sigmoid(m[i])*sigmoid(-m[i])\n",
    "            z[i,0] = m[i] - (P[i,0]*y[i])/W[i,i]\n",
    "        alpha = solveWKRR(K,W,z,lambda_)\n",
    "        iter_ = iter_ +1\n",
    "          \n",
    "    return alpha        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 44.721359549995796\n",
      "1 0.0011119556177038219\n"
     ]
    }
   ],
   "source": [
    "K0 = K_Xtr\n",
    "y_0 = trainy.reshape((trainy.shape[0],1))\n",
    "y_0 = 2*y_0-1\n",
    "n = y_0.shape[0]\n",
    "alpha = np.zeros((n,1))\n",
    "alpha = solveKLR(K0,y_0,alpha,10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.918\n"
     ]
    }
   ],
   "source": [
    "def sign(x):\n",
    "    y = x\n",
    "    n = x.shape[0]\n",
    "    for i in range(n):\n",
    "        if x[i,0] > 0:\n",
    "            y[i,0] = 1\n",
    "        else:\n",
    "            y[i,0] = 0\n",
    "    return y\n",
    "\n",
    "print('Accuracy:',np.linalg.norm(1-sign(np.dot(K0,alpha))+y_0,1)/y_0.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction2 = alpha.reshape(-1,1).T.dot(K_Xte)\n",
    "prediction2[prediction2>0] = 1\n",
    "prediction2[prediction2 <0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "predictions = np.squeeze(prediction2).astype(int)\n",
    "print(len(predictions))\n",
    "df = pd.DataFrame({'Bound': predictions,\n",
    "                   'Id': np.arange(len(predictions))})\n",
    "df = df[['Id','Bound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"spetrum_SVM.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spectrum_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def k_mers(Alphabet, k):\n",
    "    'Compute all possible words of size k from Alphabet'\n",
    "    'Store the result as a dictionnary where the keys are the words and the values ar integer Ids'\n",
    "    all_kmers_tuple = list(itertools.product(Alphabet, repeat=k))\n",
    "    all_kmers = list(map(lambda tup: ''.join(tup), all_kmers_tuple))\n",
    "    return dict(zip(all_kmers, range(len(all_kmers))))\n",
    "\n",
    "    \n",
    "def spectrum_embedding(sequence, all_kmers_dict, k):\n",
    "    'Compute the k-sepctrum embedding of sequence'\n",
    "    'The result is a vector of size vocabulary'\n",
    "    embedding = np.zeros(len(all_kmers_dict))\n",
    "    for idx in range(len(sequence)-k+1): # slidding window of size k on the sequence\n",
    "        word_id = all_kmers_dict[sequence[idx:idx+k]]\n",
    "        embedding[word_id] += 1  \n",
    "    return(embedding)\n",
    "\n",
    "def data_embedding(df, all_kmers_dict, k):\n",
    "    nb_sequences = df.shape[0]\n",
    "    embedding_dict = dict.fromkeys(range(nb_sequences))\n",
    "    for idx,sequence in enumerate(list(df['seq'])):\n",
    "        embedding = spectrum_embedding(sequence, all_kmers_dict, k)\n",
    "        embedding_dict[idx] = embedding  \n",
    "    return embedding_dict\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the embeddings for all data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "Alphabet = ['G', 'C', 'A', 'T']\n",
    "\n",
    "all_kmers_dict = k_mers(Alphabet, k)\n",
    "\n",
    "\n",
    "Xtr_embedding = data_embedding(trainx_df,all_kmers_dict,k)\n",
    "\n",
    "Xte_embedding = data_embedding(test_df,all_kmers_dict,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing tf_idf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting_array(embedding_dict, all_kmers_dict):\n",
    "    'Compute the count matrix of kmer by sequence'\n",
    "    'Output is an array of size nb_seq*vocab_size'\n",
    "    D = len(embedding_dict) # Number of documents\n",
    "    T = len(all_kmers_dict) # Vocabulary size\n",
    "    \n",
    "    output = np.zeros((D,T))\n",
    "    for document in embedding_dict.keys():\n",
    "        output[document] = embedding_dict[document]\n",
    "    return output\n",
    "\n",
    "def tf_idf(D):\n",
    "    'Input : D is a conting matrix (nb_seq*vocab_size)'\n",
    "    'Ouptut: array of tf_idf socres'\n",
    "    N = D.shape[0] # number of documents\n",
    "    idf = np.log(N/np.count_nonzero(D,axis=1)).reshape(-1,1)\n",
    "    tf = np.log(1+D/np.sum(D,axis = 1).reshape(-1,1))\n",
    "    return tf*idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the tf_idf for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf-Idf numpy.arrays -- train\n",
    "D_tr = counting_array(Xtr_embedding, all_kmers_dict)\n",
    "Xtr = tf_idf(D_tr)\n",
    "\n",
    "\n",
    "# Tf-Idf numpy.arrays -- test\n",
    "D_te = counting_array(Xte_embedding, all_kmers_dict)\n",
    "Xte = tf_idf(D_te)\n",
    "\n",
    "\n",
    "# Transforming the labels into numpy.arrays \n",
    "y0 = 2*np.array(trainy_df)[:,1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler().fit(Xtr)\n",
    "Xtr = sc.transform(Xtr)\n",
    "Xte = sc.transform(Xte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## SVM + Guaussian on tf_idf embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should parallelize this computation\n",
    "if os.path.isfile(\"tf_idf_kernel_Xtr.npy\"):\n",
    "    K_Xtr = np.load(\"tf_idf_kernel_Xtr.npy\")\n",
    "else:\n",
    "    K_Xtr = GaussKernel(Xtr, Xtr, sigma = 5)\n",
    "    np.save(\"tf_idf_kernel_Xtr.npy\",K_Xtr)\n",
    "    \n",
    "    \n",
    "if os.path.isfile(\"tf_idf_kernel_Xte.npy\"):\n",
    "    K_Xte = np.load(\"tf_idf_kernel_Xte.npy\")\n",
    "else:\n",
    "    K_Xte = GaussKernel(Xtr, Xte, sigma = 5)\n",
    "    np.save(\"tf_idf_kernel_Xte.npy\",K_Xte)\n",
    " \n",
    "\n",
    "# Transforming the labels into numpy.arrays \n",
    "y = 2*np.array(trainy_df)[:,1] - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.9372e+10 -5.2964e+11  6e+11  5e-02  4e-11\n",
      " 1:  2.4374e+10 -6.5928e+10  9e+10  6e-03  2e-10\n",
      " 2:  8.0141e+09 -2.0013e+10  3e+10  1e-03  4e-11\n",
      " 3:  1.5651e+09 -3.6132e+09  5e+09  1e-16  2e-11\n",
      " 4:  2.6005e+08 -3.5150e+08  6e+08  2e-16  9e-12\n",
      " 5:  3.7492e+07 -4.2871e+07  8e+07  2e-16  3e-12\n",
      " 6:  5.3262e+06 -6.1494e+06  1e+07  2e-16  1e-12\n",
      " 7:  7.3911e+05 -8.9905e+05  2e+06  2e-16  5e-13\n",
      " 8:  9.5832e+04 -1.3834e+05  2e+05  2e-16  2e-13\n",
      " 9:  9.1912e+03 -2.4019e+04  3e+04  2e-16  8e-14\n",
      "10: -1.1970e+03 -5.6385e+03  4e+03  2e-16  3e-14\n",
      "11: -2.0622e+03 -2.6634e+03  6e+02  2e-16  2e-14\n",
      "12: -2.1258e+03 -2.2292e+03  1e+02  2e-16  1e-14\n",
      "13: -2.1359e+03 -2.1457e+03  1e+01  2e-16  1e-14\n",
      "14: -2.1372e+03 -2.1377e+03  5e-01  2e-16  1e-14\n",
      "15: -2.1373e+03 -2.1373e+03  2e-02  2e-16  1e-14\n",
      "16: -2.1373e+03 -2.1373e+03  9e-04  2e-16  1e-14\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "alpha_star = solve_dual_SVM(K_Xtr,y, lambda_= 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = alpha_star.reshape(-1,1).T.dot(K_Xte)\n",
    "prediction[prediction>0] = 1\n",
    "prediction[prediction <0] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.499\n"
     ]
    }
   ],
   "source": [
    "train_prediction = (np.sign(alpha_star.reshape(-1,1).T.dot(K_Xtr))+1)/2\n",
    "print('Train Accuracy :',1- np.abs(train_prediction - y).sum()/y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.squeeze(prediction).astype(int)\n",
    "df = pd.DataFrame({'Bound': predictions,\n",
    "                   'Id': np.arange(len(predictions))})\n",
    "df = df[['Id','Bound']]\n",
    "\n",
    "df.to_csv(\"tf_idf_SVM.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
