{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DataHandler():\n",
    "    \n",
    "    def __init__(self, fname):\n",
    "        self.X = pd.read_csv(fname)['seq']\n",
    "        self.data = self.X\n",
    "        self.kmer_set = {}\n",
    "        self.neigborhoods = {}\n",
    "        \n",
    "        self.alph = \"GATC\"\n",
    "        self.precomputed = {}\n",
    "        \n",
    "    def spectrum_preprocess(self, k):\n",
    "        n = self.X.shape[0]\n",
    "        d = len(self.X[0])\n",
    "        embedding = [{} for x in self.X]\n",
    "        print(\"Computing kmer embedding\")\n",
    "        for i,x in enumerate(tqdm(self.X)):\n",
    "            for j in range(d - k + 1):\n",
    "                kmer = x[j: j + k]\n",
    "                if kmer in embedding[i]:\n",
    "                    embedding[i][kmer] += 1\n",
    "                else:\n",
    "                    embedding[i][kmer] = 1\n",
    "        self.data = embedding\n",
    "        \n",
    "        \n",
    "    def populate_kmer_set(self, k):\n",
    "        d = len(self.X[0])\n",
    "        idx = 0\n",
    "        print(\"Populating kmer set\")\n",
    "        for x in tqdm(self.X):\n",
    "            for j in range(d - k + 1):\n",
    "                kmer = x[j: j + k]\n",
    "                if kmer not in self.kmer_set:\n",
    "                    self.kmer_set[kmer] = idx\n",
    "                    idx +=1  \n",
    "            \n",
    "    def mismatch_preprocess(self, k, m):\n",
    "        n = self.X.shape[0]\n",
    "        d = len(self.X[0])\n",
    "        embedding = [{} for x in self.X]\n",
    "        print(\"Computing mismatch embedding\")\n",
    "        for i,x in enumerate(tqdm(self.X)):\n",
    "            for j in range(d - k + 1):\n",
    "                kmer = x[j: j + k]\n",
    "                if kmer not in self.precomputed:\n",
    "                    Mneighborhood = self.m_neighborhood(kmer, m)\n",
    "                    self.precomputed[kmer] = [self.kmer_set[neighbor] for neighbor in Mneighborhood if neighbor in self.kmer_set]\n",
    "                    \n",
    "                for idx in self.precomputed[kmer]:\n",
    "                    if idx in embedding[i]:\n",
    "                        embedding[i][idx] += 1\n",
    "                    else:\n",
    "                        embedding[i][idx] = 1\n",
    "        self.data = embedding\n",
    "            \n",
    "    def m_neighborhood(self, kmer, m):\n",
    "        mismatch_list = deque([(0, \"\")])\n",
    "        for letter in kmer:\n",
    "            num_candidates = len(mismatch_list)\n",
    "            for i in range(num_candidates):\n",
    "                mismatches, candidate = mismatch_list.popleft()\n",
    "                if mismatches < m :\n",
    "                    for a in self.alph:\n",
    "                        if a == letter :\n",
    "                            mismatch_list.append((mismatches, candidate + a))\n",
    "                        else:\n",
    "                            mismatch_list.append((mismatches + 1, candidate + a))\n",
    "                if mismatches == m:\n",
    "                    mismatch_list.append((mismatches, candidate + letter))\n",
    "        return [candidate for mismatches, candidate in mismatch_list]\n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Kernel():\n",
    "   \n",
    "    def gaussian(sigma):\n",
    "        return lambda x, y : 1/(np.sqrt(2*np.pi)*sigma) * np.exp(-np.linalg.norm(x - y)**2/(2*sigma**2))\n",
    "    \n",
    "    def linear():\n",
    "        return lambda x, y: np.dot(x, y)\n",
    "    \n",
    "    def polynomial(c, n):\n",
    "        return lambda x, y : (np.dot(x, y) + c)**n\n",
    "    \n",
    "    def spectrum():\n",
    "        def f(x, y):\n",
    "            prod_scal = 0\n",
    "            for kmer in x:\n",
    "                if kmer in y:\n",
    "                    prod_scal += x[kmer]*y[kmer]\n",
    "            return prod_scal\n",
    "        return f\n",
    "    \n",
    "    def mismatch():\n",
    "        def f(x, y):\n",
    "            prod_scal = 0\n",
    "            for idx in x:\n",
    "                if idx in y:\n",
    "                    prod_scal += x[idx]*y[idx]\n",
    "            return prod_scal\n",
    "        return f\n",
    "    \n",
    "    def sparse_gaussian(sigma):\n",
    "        def f(x, y):\n",
    "            ps = Kernel.mismatch()\n",
    "            norm = ps(x, x) - 2*ps(x, y) + ps(y,y)\n",
    "            return 1/(np.sqrt(2*np.pi)*sigma) * np.exp(-norm/(2*sigma**2))\n",
    "        return f\n",
    "    \n",
    "    def sparse_poly(c, n):\n",
    "        def f(x, y):\n",
    "            ps = Kernel.mismatch()\n",
    "            return (ps(x,y) + c)**n\n",
    "        return f\n",
    "    \n",
    "    def __init__(self, func, normalized = False):\n",
    "        self.kernel = func\n",
    "        self.normalized = normalized\n",
    "        self.diag = np.array([])\n",
    "        \n",
    "    def gram(self, data):\n",
    "        n = len(data)\n",
    "        K = np.zeros((n, n))\n",
    "        print(\"Computing Gram Matrix\")\n",
    "        for i in tqdm(range(n)):\n",
    "            for j in range(i+1):\n",
    "                prod_scal = self.kernel(data[i], data[j])\n",
    "                K[i, j] = prod_scal\n",
    "                K[j, i] = prod_scal\n",
    "        \n",
    "        if self.normalized:\n",
    "            self.diag = np.sqrt(np.diag(K))\n",
    "            print(self.diag.shape)\n",
    "            for i in range(n):\n",
    "                K[i, :] = K[i,:]/self.diag[i]\n",
    "                K[:, i] = K[:, i]/self.diag[i]\n",
    "            \n",
    "        return K\n",
    "    \n",
    "    def eval_f(self, x, alpha, data):\n",
    "        if self.normalized:\n",
    "            square_norm_x = np.sqrt(self.kernel(x, x))\n",
    "            result = np.sum([(alpha[i]*self.kernel(x, xi))/(square_norm_x * self.diag[i]) for i, xi in enumerate(data)])\n",
    "        else:\n",
    "            result =  np.sum([alpha[i]*self.kernel(x, xi) for i, xi in enumerate(data)])\n",
    "        return result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from LargeMargin import LargeMargin\n",
    "#from Kernel import Kernel\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def project(v):\n",
    "        \n",
    "        mu = list(v)\n",
    "        mu.sort()\n",
    "        cumul_sum = np.cumsum(mu)\n",
    "        rho = np.max([j for j in range(0, len(mu)) if mu[j] - 1/(j+1)*(cumul_sum[j] - 1) > 0])\n",
    "        \n",
    "        theta = 1/(rho+1)*(cumul_sum[rho] - 1)\n",
    "        return np.array([max(0, vi - theta) for vi in v])\n",
    "\n",
    "def MKL(kernels, y, lmda, T):\n",
    "    \n",
    "    m = len(kernels)\n",
    "    d = np.array([1/m for k in range(m)])\n",
    "    \n",
    "    for t in range(T):\n",
    "        \n",
    "        K = np.zeros_like(kernels[0])\n",
    "        for i, Km in enumerate(kernels):\n",
    "            K = K + d[i]*Km\n",
    "        \n",
    "        alpha = LargeMargin.SVM(K, y, lmda) #Resoud pour la somme\n",
    "        \n",
    "        \n",
    "        grad = [-0.5*lmda*np.dot(alpha.T, np.dot(Km, alpha))[0][0] for Km in kernels]\n",
    "        step = 0.01\n",
    "        d = project(d - step*np.array(grad)) #Projette le gradient sur le simplexe\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import solvers, matrix, spmatrix, sparse\n",
    "import numpy as np\n",
    "\n",
    "class LargeMargin():\n",
    "    \n",
    "    def SVM(K, y, lmda):\n",
    "    \n",
    "        print(\"Optimizing\")\n",
    "    \n",
    "        solvers.options['show_progress'] = False\n",
    "    \n",
    "        n = len(y)\n",
    "        q = -matrix(y, (n, 1), tc='d')\n",
    "        h = matrix(np.concatenate([np.ones(n)/(2*lmda*n), np.zeros(n)]).reshape((2*n, 1)))\n",
    "        P = matrix(K)\n",
    "        Gtop = spmatrix(y, range(n), range(n))\n",
    "        G = sparse([Gtop, -Gtop])\n",
    "\n",
    "    \n",
    "        sol = solvers.qp(P, q, G, h)['x']\n",
    "    \n",
    "        return sol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from LargeMargin import LargeMargin\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def write_predictions(predictions, out_fname):\n",
    "    \n",
    "    data = [[int(np.abs((pred+1)//2))] for i, pred in enumerate(predictions)]\n",
    "    data = np.concatenate([[['Bound']], data])\n",
    "    \n",
    "                \n",
    "    data_frame = pd.DataFrame(data=data[1:,:], columns=data[0])\n",
    "    data_frame.index.name = 'Id'\n",
    "    data_frame.to_csv(out_fname)\n",
    "    \n",
    "    \n",
    "def kernel_train(kernel, training_data, ytrain, lmda):\n",
    "    \n",
    "    K = kernel.gram(training_data)\n",
    "    alpha = LargeMargin.SVM(K, ytrain, lmda)\n",
    "    return alpha\n",
    "\n",
    "def kernel_predict(kernel, alpha, training, test):\n",
    "    \n",
    "    predict = []\n",
    "    for x in tqdm(test):\n",
    "        predict.append(np.sign(kernel.eval_f(x, alpha, training)))\n",
    "    return predict\n",
    "\n",
    "def score(predict, yreal):\n",
    "    \n",
    "    return sum([int(predict[i]==yreal[i]) for i in range(len(yreal))])/len(yreal)\n",
    "\n",
    "def split_data(dataset, y, k, m):\n",
    "    \n",
    "    dataset.populate_kmer_set(k)\n",
    "    dataset.mismatch_preprocess(k, m)\n",
    "    idx = range(len(dataset.data))\n",
    "    pairs = []\n",
    "    data_tranches = [idx[500*i : 500*i+ 500] for i in range(4)]\n",
    "    label_tranches = [y[500*i: 500*i + 500] for i in range(4)]\n",
    "    for i in range(4):\n",
    "        test, ytest = data_tranches[i], label_tranches[i]\n",
    "        train = np.concatenate([data_tranches[j] for j in range(4) if j != i])\n",
    "        ytrain = np.concatenate([label_tranches[j] for j in range(4) if j != i])\n",
    "        \n",
    "        pairs.append((train, ytrain, test, ytest))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "        DATASET 0\n",
      "------------------------------------------------------------\n",
      "\n",
      "2000\n",
      "Populating kmer set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 32595.60it/s]\n",
      "  1%|          | 25/3000 [00:00<00:11, 249.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing mismatch embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:06<00:00, 488.55it/s]\n",
      "  2%|▏         | 47/3000 [00:00<00:06, 468.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Gram Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [06:16<00:00,  7.98it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 28696.40it/s]\n",
      "  0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating kmer set\n",
      "Computing mismatch embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:08<00:00, 343.01it/s]\n",
      "  2%|▏         | 53/3000 [00:00<00:05, 526.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Gram Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [03:31<00:00, 14.17it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 27152.34it/s]\n",
      "  0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating kmer set\n",
      "Computing mismatch embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:11<00:00, 262.36it/s]\n",
      "  3%|▎         | 85/3000 [00:00<00:03, 843.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Gram Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [01:45<00:00, 28.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 918.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "        KAGGLEIZER\n",
      "------------------------------------------------------------\n",
      "\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# from DataHandler import DataHandler\n",
    "# from LargeMargin import LargeMargin\n",
    "# from Kernel import Kernel\n",
    "# from utils import kernel_train, kernel_predict, write_predictions\n",
    "\n",
    "\n",
    "\n",
    "print('''\n",
    "------------------------------------------------------------\n",
    "        DATASET 0\n",
    "------------------------------------------------------------\n",
    "''')\n",
    "\n",
    "fname = ''\n",
    "dataset = DataHandler('Xtr.csv')\n",
    "\n",
    "labels = pd.read_csv('Ytr.csv')\n",
    "print(len(labels['Bound']))\n",
    "y = 2.0*np.array(labels['Bound']) - 1\n",
    "\n",
    "test = DataHandler('Xte.csv')\n",
    "\n",
    "dataset.X = pd.concat([dataset.X, test.X], axis = 0, ignore_index = True)\n",
    "\n",
    "\n",
    "dataset.populate_kmer_set(k = 9)\n",
    "dataset.mismatch_preprocess(k=9, m=1)\n",
    "K9 = Kernel(Kernel.mismatch()).gram(dataset.data)\n",
    "\n",
    "dataset.populate_kmer_set(k = 10)\n",
    "dataset.mismatch_preprocess(k=10, m=1)\n",
    "K10 = Kernel(Kernel.mismatch()).gram(dataset.data)\n",
    "\n",
    "dataset.populate_kmer_set(k = 11)\n",
    "dataset.mismatch_preprocess(k=11, m=1)\n",
    "K11 = Kernel(Kernel.mismatch()).gram(dataset.data)\n",
    "\n",
    "\n",
    "K = K9 + K10 + K11\n",
    "\n",
    "training = [i for i in range(2000)]\n",
    "testing = [i for i in range(2000, 3000)]\n",
    "\n",
    "lmda = 0.0000001\n",
    "\n",
    "\n",
    "alpha = LargeMargin.SVM(K[training][:, training], y, lmda)\n",
    "\n",
    "pred0 = []\n",
    "for i in tqdm(testing):\n",
    "    val = 0\n",
    "    for k, j in enumerate(training):\n",
    "        val += alpha[k]*K[i, j]\n",
    "    pred0.append(np.sign(val))\n",
    "    #pred0 = np.array(pred0)\n",
    "\n",
    "\n",
    "# print('''\n",
    "# ------------------------------------------------------------\n",
    "#         DATASET 1\n",
    "# ------------------------------------------------------------\n",
    "# ''')\n",
    "\n",
    "# fname = '1'\n",
    "# dataset = DataHandler('Data/Xtr'+fname+'.csv')\n",
    "\n",
    "# labels = pd.read_csv('data/Ytr'+fname+'.csv')\n",
    "# y = 2.0*np.array(labels['Bound']) - 1\n",
    "\n",
    "# test = DataHandler('data/Xte'+fname+'.csv')\n",
    "\n",
    "\n",
    "# dataset.X = pd.concat([dataset.X, test.X], axis = 0, ignore_index = True)\n",
    "\n",
    "\n",
    "# dataset.populate_kmer_set(k = 9)\n",
    "# dataset.mismatch_preprocess(k=9, m=1)\n",
    "# K9 = Kernel(Kernel.mismatch()).gram(dataset.data)\n",
    "\n",
    "# dataset.populate_kmer_set(k = 10)\n",
    "# dataset.mismatch_preprocess(k=10, m=1)\n",
    "# K10 = Kernel(Kernel.mismatch()).gram(dataset.data)\n",
    "\n",
    "# dataset.populate_kmer_set(k = 11)\n",
    "# dataset.mismatch_preprocess(k=11, m=1)\n",
    "# K11 = Kernel(Kernel.mismatch()).gram(dataset.data)\n",
    "\n",
    "\n",
    "# K = K9 + K10 + K11\n",
    "\n",
    "# training = [i for i in range(2000)]\n",
    "# testing = [i for i in range(2000, 3000)]\n",
    "\n",
    "# lmda = 0.833\n",
    "\n",
    "\n",
    "# alpha = LargeMargin.SVM(K[training][:, training], y, lmda)\n",
    "\n",
    "# pred1 = []\n",
    "# for i in tqdm(testing):\n",
    "#     val = 0\n",
    "#     for k, j in enumerate(training):\n",
    "#         val += alpha[k]*K[i, j]\n",
    "#     pred1.append(np.sign(val))\n",
    "\n",
    "\n",
    "# print('''\n",
    "# ------------------------------------------------------------\n",
    "#         DATASET 2\n",
    "# ------------------------------------------------------------\n",
    "# ''')\n",
    "\n",
    "# fname = ''\n",
    "# dataset = DataHandler('data/Xtr'+fname+'.csv')\n",
    "\n",
    "# labels = pd.read_csv('data/Ytr'+fname+'.csv')\n",
    "# y = 2.0*np.array(labels['Bound']) - 1\n",
    "\n",
    "# test = DataHandler('data/Xte'+fname+'.csv')\n",
    "\n",
    "    \n",
    "# dataset.populate_kmer_set(12)\n",
    "# test.kmer_set = dataset.kmer_set\n",
    "\n",
    "# dataset.mismatch_preprocess(12 , 0)\n",
    "# test.mismatch_preprocess(12, 0)\n",
    "\n",
    "# kernel = Kernel(Kernel.sparse_gaussian(7.8))\n",
    "\n",
    "\n",
    "# lmda = 0.00000001\n",
    "\n",
    "# alpha = kernel_train(kernel, dataset.data, y, lmda)\n",
    "# pred2 = kernel_predict(kernel, alpha, dataset.data, test.data)\n",
    "\n",
    "\n",
    "print('''\n",
    "------------------------------------------------------------\n",
    "        KAGGLEIZER\n",
    "------------------------------------------------------------\n",
    "''')\n",
    "\n",
    "out_fname = \"Yte.csv\"\n",
    "#pred0 = np.array(pred0, dtype=np.int)\n",
    "predictions = pred0 \n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] < 0:\n",
    "        predictions[i] = 0\n",
    "    else:\n",
    "        predictions[i] = 1\n",
    "        \n",
    "        \n",
    "    \n",
    "print(len(predictions))\n",
    "# test['Bound'] = predictions\n",
    "# subm = test[['Id','Bound']]\n",
    "\n",
    "write_predictions(predictions, out_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Bound': predictions,\n",
    "                   'Id': np.arange(1000)})\n",
    "df = df[['Id','Bound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ModelPredictons.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
